# Multi-Cloud ML Model Deployment Project

This project explores the running and deployment of a machine learning model across different cloud platforms, including Google Colab, Google Cloud Platform (GCP), Amazon Web Services (AWS) SageMaker, AWS EC2, and AWS Comprehend. By leveraging various cloud services, we aim to evaluate their capabilities, performance, and suitability for hosting and deploying machine learning models.

## Team Members

- **Dhairyashil**
  - Role: Conclusion
    
- **Kartik**
  - Role: Comprehend
    
- **Saksham**
  - Role: Introduction and Google Cloud Platform
    
- **Pranjal**
  - Role: EC2

## Overview

The project involves the following steps:

1. Running the ML model on Google Colab for rapid prototyping and experimentation.
2. Deploying the ML model on Google Cloud Platform using managed services such as AI Platform for training and prediction.
3. Hosting the ML model on AWS SageMaker, a fully managed service for building, training, and deploying ML models at scale.
4. Deploying the ML model on AWS EC2 instances for more customizable infrastructure configurations.
5. Utilizing AWS Comprehend, a natural language processing (NLP) service, for text analysis tasks related to the ML model.

## Usage

1. Clone the repository:

```bash
git clone https://github.com/your-username/multi-cloud-ml-deployment.git
```

2. Install all the dependencies from requirement.txt:

```bash
pip install -r requirement.txt
```
